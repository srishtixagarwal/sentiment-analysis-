{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeab16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snscrape  #package for social network scrape\n",
    "!pip install nltk    #package for NLP\n",
    "!pip install preprocessor\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2b4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import os\n",
    "from re import M\n",
    "from threading import Lock\n",
    "import concurrent.futures\n",
    "from concurrent.futures import as_completed\n",
    "import subprocess\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e40e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/srishtiagarwal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d01102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query__ = \"(#cancelculture) lang:en until:2022-12-20 since:2022-01-01\"   \n",
    "# tweets_ =[]\n",
    "# limit=30000\n",
    "# count=0\n",
    "# for tweet in sntwitter.TwitterSearchScraper(query__).get_items():\n",
    "#        #print(vars(tweet))\n",
    "#        #break\n",
    "#         count+=1\n",
    "#         if count==limit:\n",
    "#          break\n",
    "#         else:\n",
    "#          tweets_.append([tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ff9e651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []  \n",
    "query1 = \"(#cancelculture) lang:en until:2022-12-20 since:2022-10-01\"   \n",
    "query2 = \"(#cancelculture) lang:en until:2022-9-30 since:2022-07-01\"   \n",
    "query3 = \"(#cancelculture) lang:en until:2022-06-30 since:2022-04-01\"   \n",
    "query4 = \"(#cancelculture) lang:en until:2022-03-31 since:2022-01-01\"   \n",
    "query5 = \"(#cancelculture) lang:en until:2021-12-31 since:2021-10-01\"   \n",
    "query6 = \"(#cancelculture) lang:en until:2021-9-30 since:2021-07-01\"   \n",
    "query7 = \"(#cancelculture) lang:en until:2021-06-30 since:2021-04-01\"   \n",
    "query8 = \"(#cancelculture) lang:en until:2021-03-31 since:2021-01-01\"    \n",
    "\n",
    "for i in range(1, 9):\n",
    "  text = \"query\"+str(i)\n",
    "  queries.append(eval(text))  \n",
    "\n",
    "tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc61dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []  \n",
    "query1 = \"armie hammer lang:en until:2021-01-31 since:2021-01-15\"   \n",
    "query2 = \"armie hammer lang:en until:2021-02-15 since:2021-02-01\"   \n",
    "  \n",
    "\n",
    "for i in range(1, 3):\n",
    "  text = \"query\"+str(i)\n",
    "  queries.append(eval(text))  \n",
    "\n",
    "tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []  \n",
    "query1 = \"armie hammer lang:en until:2020-12-31 since:2020-12-01\"   \n",
    "query2 = \"armie hammer lang:en until:2020-11-30 since:2020-11-01\"   \n",
    "  \n",
    "\n",
    "for i in range(1, 3):\n",
    "  text = \"query\"+str(i)\n",
    "  queries.append(eval(text))  \n",
    "\n",
    "tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "33f047c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(query, limit):\n",
    "   # os.system(f\"rm tempTests/{case[13:-4]}.out\")                    #removing outputs from previous run if any\n",
    "    output = \"\"\n",
    "    tweets = []\n",
    "    count = 0\n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "      count+=1\n",
    "      if count==limit:\n",
    "        break\n",
    "      else:\n",
    "        tweets.append([tweet.content])    \n",
    "    return pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34975f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def main():\n",
    "   \n",
    "tweets=pd.DataFrame()\n",
    "limit = 20000\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        #max_workers decides the number of threads that will be used in execution\n",
    "        futures= [executor.submit(run_test, query, limit) for query in queries]\n",
    "        #futures is calling run_test for each case (every testcase)\n",
    "        for future in as_completed(futures):    \n",
    "        #wait for all tasks to complete by getting all results  \n",
    "            try:  \n",
    "                data =future.result() \n",
    "\n",
    "                tweets= tweets.append(data)\n",
    "                \n",
    "                print(f\"Finished running \") \n",
    "            except Exception as exc:\n",
    "                print(f\"Test Hung \\u23F3\")\n",
    "                print(exc)\n",
    "     \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12816a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.columns=['tweet_text']\n",
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.DataFrame(tweets, columns=['tweet_text'])\n",
    "df_orig.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "61e03b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(sen):\n",
    "    '''clean the data, leave only 2 or more char long non-stepwords composed of A-Z and a-z only in lowercase'''\n",
    "    sentence=sen.lower()\n",
    "    \n",
    "    #remove RT\n",
    "    sentence=re.sub('RT @\\w+: ',\" \", sentence)\n",
    "    \n",
    "    #remove punctuations and numbers\n",
    "    sentence = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)  # When we remove apostrophe from the word \"Mark's\", the apostrophe is replaced by an empty space. Hence, we are left with single character \"s\" that we are removing here.\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4b0ebc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = []\n",
    "\n",
    "for tweet in df_orig['tweet_text']:\n",
    "    cleaned_tweet = preprocess_tweet(tweet)\n",
    "    cleaned_tweets.append(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['cleaned']=pd.DataFrame(cleaned_tweets)\n",
    "df_orig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7d504b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative, Positive, Neutral and Compound values\n",
    "\n",
    "df_orig[['polarity', 'subjectivity']] = df_orig['cleaned'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in df_orig['cleaned'].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    if comp <= -0.05:\n",
    "        df_orig.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif comp >= 0.05:\n",
    "        df_orig.loc[index, 'sentiment'] = \"positive\"\n",
    "    else:\n",
    "        df_orig.loc[index, 'sentiment'] = \"neutral\"\n",
    "    df_orig.loc[index, 'neg'] = neg\n",
    "    df_orig.loc[index, 'neu'] = neu\n",
    "    df_orig.loc[index, 'pos'] = pos\n",
    "    df_orig.loc[index, 'compound'] = comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48534ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a00e0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New data frames for sentiments: positive, negative and neutral)\n",
    "\n",
    "df_orig_negative = df_orig[df_orig[\"sentiment\"]==\"negative\"]\n",
    "df_orig_positive = df_orig[df_orig[\"sentiment\"]==\"positive\"]\n",
    "df_orig_neutral = df_orig[df_orig[\"sentiment\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7b292df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting values \n",
    "\n",
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count_values for sentiment\n",
    "count_values_in_column(df_orig,\"sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
